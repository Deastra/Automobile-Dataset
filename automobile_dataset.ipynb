{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Automobile_data.csv\",na_values=[\"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df=data.copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data, diag_kind='kde', markers='+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data._get_numeric_data().columns:\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 4))\n",
    "    sns.histplot(data[i], bins=10, ax=axes[0])\n",
    "    axes[0].set_title(i)\n",
    "    \n",
    "    sns.boxplot(data[i], ax=axes[1])\n",
    "    axes[1].set_title(i)\n",
    "   \n",
    "    sns.kdeplot(data[i], ax=axes[2],fill=True)\n",
    "    axes[2].set_title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data[data['price'].isnull()].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"index\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()/len(data)*100\n",
    "# normalized-losses has null values of 18%, so it should be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"normalized-losses\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['num-of-doors'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['num-of-doors'].replace({\"four\":4,'two':2},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['num-of-doors'].fillna(data['num-of-doors'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"horsepower\"].fillna(data[\"horsepower\"].mean(),inplace=True)\n",
    "data[\"bore\"].fillna(data[\"bore\"].mean(),inplace=True)\n",
    "data[\"stroke\"].fillna(data[\"stroke\"].mean(),inplace=True)\n",
    "data[\"peak-rpm\"].fillna(data[\"peak-rpm\"].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()\n",
    "# no missing values remained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols=data._get_numeric_data().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    sns.boxplot(data[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As it seems, there are plenty of outliers\n",
    "# Two functions for managing outliers\n",
    "def outlier_thresholds(dataframe, col_name, q1=0.25, q3=0.75):\n",
    "    quartile1 = dataframe[col_name].quantile(q1)\n",
    "    quartile3 = dataframe[col_name].quantile(q3)\n",
    "    interquantile_range = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * interquantile_range\n",
    "    low_limit = quartile1 - 1.5 * interquantile_range\n",
    "    return low_limit, up_limit\n",
    "\n",
    "def replace_with_thresholds(dataframe, col_name,up=0.25, low=0.75):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name,up,low)\n",
    "    if low_limit > 0:\n",
    "        dataframe.loc[(dataframe[col_name] < low_limit), col_name] = low_limit\n",
    "        dataframe.loc[(dataframe[col_name] > up_limit), col_name] = up_limit\n",
    "    else:\n",
    "        dataframe.loc[(dataframe[col_name] > up_limit), col_name] = up_limit\n",
    "        \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all outliers except in 'price' column\n",
    "for col in num_cols[:-1]:\n",
    "    data=replace_with_thresholds(data,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    sns.boxplot(data[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols=data.select_dtypes(\"object\").columns\n",
    "obj_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"make\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in obj_cols:\n",
    "    print(data[col].value_counts())\n",
    "    print(\"################\")\n",
    "    \n",
    "# Some values take place less than 5 percentage of the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation dataframe of df\n",
    "corr=data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation dataframe of df where correlation is higher than 0.5 (for price)\n",
    "corr=corr[abs(corr['price'])>0.5]\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix of highest corr_rate for price\n",
    "f, ax = plt.subplots(figsize= [20,13])\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", ax=ax, cmap = \"magma\" )\n",
    "ax.set_title(\"Correlation Matrix\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T\n",
    "# Price column has a very large std compared to its mean\n",
    "# So, price column needs to be normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=replace_with_thresholds(data,\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score,accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_modeling(df, Y, algo):\n",
    "    X=df.drop(Y, axis=1)\n",
    "    Y=df[[Y]]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.20, random_state=42)\n",
    "    model=algo.fit(X_train, Y_train)\n",
    "    Y_pred=algo.predict(X_test)\n",
    "    error=np.sqrt(mean_squared_error(Y_test,Y_pred))\n",
    "    score_algo=algo.score(X_test, Y_test)\n",
    "    r2=r2_score(Y_test,Y_pred)\n",
    "    print(f'{type(model).__name__}\\n---Error: {error}\\n---Algo_Score: {score_algo}\\n---R2_Score: {r2}')    \n",
    "    print('----------------------------------------------------')\n",
    "    return (type(model).__name__, error,score_algo,r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[LinearRegression(),Ridge(),Lasso(),ElasticNet()]\n",
    "results={ 'model_name':[], 'Error':[],\"Model_Score\":[],\"R2_Score\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    res=reg_modeling(data,\"price\",m)\n",
    "    results['model_name'].append(res[0])\n",
    "    results[\"Error\"].append(res[1])\n",
    "    results[\"Model_Score\"].append(res[2])\n",
    "    results[\"R2_Score\"].append(res[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters={\n",
    "    'Ridge' : {\n",
    "        'model': Ridge(),\n",
    "        'params': {'alpha': [0.1, 0.01, 0.005, 0.05, 0.001 ,0.2, 0.3, 0.5, 0.8, 0.9, 1], \n",
    "                   'solver': ['auto', 'svd', 'cholesky']}},\n",
    "    'Lasso': {\n",
    "        'model': Lasso(),\n",
    "        'params': {'selection': ['cyclic', 'random'], \n",
    "                  'alpha': [0.1,0.01, 0.005, 0.05, 0.001 ,0.2, 0.3, 0.5, 0.8, 0.9, 1]}},\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeRegressor(),\n",
    "        'params': {'criterion': ['mse', 'friedman_mse', 'mae', 'poisson'],\n",
    "                   'splitter': ['best', 'random']}}, \n",
    "    'KNeighbors': {\n",
    "        'model': KNeighborsRegressor(), \n",
    "        'params': {'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], \n",
    "                  'weights': ['uniform', 'distance'],\n",
    "                  'n_neighbors': [3, 4, 5]}},\n",
    "    'ElasticNet': {\n",
    "        'model': ElasticNet(), \n",
    "        'params': {'alpha': [0.1,0.01, 0.005, 0.05, 0.001 ,0.2, 0.3, 0.5, 0.8, 0.9, 1],\n",
    "                  'selection': ['cyclic', 'random']}}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tunings(df,Y, model_params):\n",
    "    X=df.drop(Y, axis=1)\n",
    "    Y=df[[Y]]\n",
    "    results=[]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "    for model_name, mp in model_params.items():\n",
    "        clf=GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=True)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        Y_train_pred=clf.predict(X_train)\n",
    "        Y_test_pred=clf.predict(X_test)\n",
    "        train_error=np.sqrt(mean_squared_error(Y_train, Y_train_pred))\n",
    "        train_score=clf.score(X_train, Y_train)\n",
    "        test_error=np.sqrt(mean_squared_error(Y_test, Y_test_pred))\n",
    "        test_score=clf.score(X_test, Y_test)\n",
    "        #score_algo=algo.score(X_test, Y_test)\n",
    "        r2=r2_score(Y_test,Y_test_pred)\n",
    "        \n",
    "        print(model_name)\n",
    "        #print('Train Rmse: {}'.format(train_error))\n",
    "        #print('Train Score: {}'.format(train_score))\n",
    "        print('Test Rmse : {}'.format(test_error))\n",
    "        print('Test Score: {}'.format(test_score))\n",
    "        print(\"R2_score  : {}\".format(r2))\n",
    "        print('------------------------------------------------------')\n",
    "        results.append({'model': model_name, \n",
    "                        #'Train Error': train_error,\n",
    "                        #'Train Score': train_score,\n",
    "                        'Test Error': test_error,\n",
    "                        'Test Score': test_score,\n",
    "                        'best_score': clf.best_score_,\n",
    "                        'best_params': clf.best_params_})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunings=model_tunings(data,'price',model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_gbm(df, Y):\n",
    "    #df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    lgbm=LGBMRegressor()\n",
    "    X=df.drop(Y, axis=1)\n",
    "    Y=df[[Y]]\n",
    "    X_train, X_test, Y_train, Y_test=train_test_split(X, Y, random_state=42, test_size=0.20)\n",
    "    lgbm.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred=lgbm.predict(X_test,num_iteration=lgbm.best_iteration_)\n",
    "    print(\"Light_Score:: \",lgbm.score(X_test,Y_test))\n",
    "    print(\"Error:: \",(np.sqrt(mean_squared_error(Y_test, Y_pred))))\n",
    "    print(\"R2_Score:: \",(r2_score(Y_test,Y_pred)))\n",
    "    #print(Y_pred)\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=light_gbm(data,\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_gbm_tuning(df, Y):\n",
    "    #df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    X=df.drop(Y, axis=1)\n",
    "    Y=df[[Y]]\n",
    "    X_train, X_test, Y_train, Y_test=train_test_split(X, Y, random_state=42, test_size=0.20)\n",
    "    lgbm_grid={\n",
    "    'colsample_bytree':[0.4, 0.5, 0.6, 0.9, 1],\n",
    "    'learning_rate':[0.01, 0.1, 0.5, 1],\n",
    "           'n_estimators':[20, 40, 100, 200, 500, 1000],\n",
    "           'max_depth':[1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "\n",
    "    lgbm=LGBMRegressor()\n",
    "\n",
    "    lgbm_cv_model=GridSearchCV(lgbm, lgbm_grid, cv=10,\n",
    "                           n_jobs=-1, verbose=2)\n",
    "\n",
    "    lgbm_cv_model.fit(X_train, Y_train)\n",
    "\n",
    "    print(\"Parameters:: \",lgbm_cv_model.best_params_)\n",
    "    print(\"Score::      \",lgbm_cv_model.best_score_)\n",
    "    return lgbm_cv_model.best_params_,lgbm_cv_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params,light_score=light_gbm_tuning(data,\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best result so far is below::\n",
    "\n",
    "model: ElasticNet (GridSearch CV tuning)    \n",
    "\n",
    "***Test Rmse : 1531.7349767798682***                                                                                           \n",
    "\n",
    "***Test Score: 0.9674273751102496***       \n",
    "\n",
    "***R2_score  : 0.9674273751102496***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
